
import os
import re
import numpy as np
import stgeotk as stg

from util import logger, int_to_string, Timer

ptcl_file_suffix = "Ptcls"
csv_file_suffix = "TimeStepData"
stereonet_export_suffix = "PtclStereonet"
stereonet_export_filetype = "svg"


class ParticleAnalystBase:
    """
    Base class for particle structural geology data analysis
    for export files generated by FELSPA modelling package.
    """

    def __init__(self):
        self.stereonet = stg.Stereonet()
        self.extractor = None
        self.data_mask = None
        self.eigenvectors = None
        self._size = 0
        self.data = {}
        self.export_path = ""

    @property
    def figure(self):
        # get the stereonet figure
        return self.stereonet.figure

    def __getitem__(self, key):
        if key in ["xyz", "strike", "dip", "foliation_strike", "foliation_dip", "flinn", "lambda1", "lambda2", "lambda3", "deformation_intensity"]:
            return self.data[key]
        return self.extractor.get_dataset(key)

    def _do_load(self):
        '''
        - load xyz-coordinate data
        - load the strike and dip of the level set surface,
            computed from level_set_normal
        '''
        if self.extractor is None:
            raise RuntimeError(
                "VtkUnstructuredGridExtractor is not initialized")
        self._size = self.extractor.get_dataset("id").shape[0]
        logger.info("The dataset has %d elements.", self._size)
        self.data_mask = np.ones(self._size, dtype=bool)

        # cache interface strike and dip, geologically this is the bedding
        lvset_normal = self.extractor.get_dataset("level_set_normal")
        lvset_trend, lvset_plunge = stg.cartesian_to_line(lvset_normal).T
        self.data["strike"] = (lvset_trend + 90.0) % 360.0
        self.data["dip"] = 90.0 - lvset_plunge
        # cache spatial coordinates
        self.data["xyz"] = self.extractor.get_xyz()

        # obtain everything related to strain ellipsoid
        self.deformation_analysis()

    def apply_dataset_mask(self, *masks):
        if not hasattr(self, "extractor"):
            raise RuntimeError(
                "File number is not given. Call load_file_number()")
        for m in masks:
            self.data_mask &= m

    def clear_dataset_mask(self):
        self.data_mask = np.ones(self._size, dtype=bool)

    def deformation_analysis(self):
        Fs = self.extractor.get_dataset("deformation_gradient")
        with Timer("Computing strain ellipsoids") as _:
            self.eigenvectors = stg.strain_ellipsoid(Fs)
            if ~np.all(np.linalg.norm(self.eigenvectors, axis=2) > 0):
                raise RuntimeError(
                    "some eigenvectors has non-physical zero length.")

        # precompute foliation strike and dip
        foli_normal_strike, foli_normal_dip = stg.cartesian_to_line(
            self.eigenvectors[:, 0, :]).T
        self.data["foliation_strike"] = (foli_normal_strike + 90.0) % 360.0
        self.data["foliation_dip"] = 90.0 - foli_normal_dip

        # flinn values:
        l3 = np.linalg.norm(self.eigenvectors[:, 0, :], axis=1)
        l2 = np.linalg.norm(self.eigenvectors[:, 1, :], axis=1)
        l1 = np.linalg.norm(self.eigenvectors[:, 2, :], axis=1)

        self.data["flinn"] = l1 * l3 / l2 / l2
        self.data["lambda1"], self.data["lambda2"], self.data["lambda3"] = l1, l2, l3

        #  deformation intensity
        self.data["deformation_intensity"] = np.sqrt((l2/l3 - 1)**2 + (l1/l2 - 1)**2)
        

    def plot_lineation(self, color_axis, color_axis_legend, **kwargs):
        mask = self.data_mask
        dataset_legend = kwargs.get("dataset_legend",  "lineation")
        draw_contour = kwargs.get("contour",  False)
        cmap_limits = kwargs.get(
            "cmap_limits", [min(color_axis[mask]), max(color_axis[mask])])

        lineation = self.eigenvectors[:, 2, :]

        dataset = stg.LineData()
        dataset.load_data(lineation[mask], dataset_legend,
                          color_axis[mask], color_axis_legend)

        flinn = self.data["flinn"][mask]

        line_plot = stg.LinePlot(self.stereonet, dataset,
                                 cmap="RdYlGn", marker="^", s=100*flinn,
                                 edgecolors="black", linewidth=0.8,
                                 cmap_center=0.0, cmap_limits=cmap_limits)

        if draw_contour:
            contour_data = stg.ContourData(
                dataset, counting_method="fisher", auto_k_optimization=True)
            contour_plot = stg.ContourPlot(
                self.stereonet, contour_data, alpha=0.9)
            self.stereonet.append_plot(contour_plot)

        self.stereonet.append_plot(line_plot)
        self.stereonet.generate_plots(False)

        # return the lineation filter
        return mask

    def plot_foliation(self, color_axis, color_axis_legend, **kwargs):
        mask = self.data_mask
        dataset_legend = kwargs.get("dataset_legend",  "foliation")
        draw_contour = kwargs.get("contour",  False)
        foliation_normal = self.eigenvectors[:, 0, :]
        draw_contour = True
        flinn = self.data["flinn"][mask]

        dataset = stg.LineData()
        # dataset.load_data(foliation_normal[mask], dataset_legend, color_axis[mask], color_axis_legend)

        dataset.load_data(foliation_normal[mask], dataset_legend)

        line_plot = stg.LinePlot(self.stereonet, dataset,
                                 cmap="RdYlGn", marker=".", s=5,
                                 edgecolors="black", linewidth=0.05)

        if draw_contour:
            contour_data = stg.ContourData(
                dataset, counting_method="fisher", auto_k_optimization=True)
            contour_plot = stg.ContourPlot(
                self.stereonet, contour_data, alpha=0.9)
            self.stereonet.append_plot(contour_plot)

        self.stereonet.append_plot(line_plot)
        self.stereonet.generate_plots(False)

        # return the lineation filter
        # return mask

    def filter_by_bounding_box(self, lower_limits, upper_limits):
        if not hasattr(self, "extractor"):
            raise RuntimeError(
                "File number is not given. Call load_file_number()")
        for idim in range(0, 3):
            self.data_mask &= self.data["xyz"][:, idim] >= lower_limits[idim]
            self.data_mask &= self.data["xyz"][:, idim] <= upper_limits[idim]

    def filter_by_distance_to_plane(self, plane_center, plane_normal, max_distance, sign):
        if not hasattr(self, "extractor"):
            raise RuntimeError(
                "File number is not given. Call load_file_number()")

        n_data_points = self.data["xyz"][0].size
        distance_to_plane = np.zeros(n_data_points)
        for idim in range(0, 3):
            distance_to_plane = distance_to_plane + (
                self.data["xyz"][idim] - plane_center[idim]) * plane_normal[idim]

        self.data_mask = np.logical_and(
            self.data_mask, np.abs(distance_to_plane) <= max_distance)

        if sign == '+':
            self.data_mask = np.logical_and(
                self.data_mask, distance_to_plane >= 0.0)
        elif sign == '-':
            self.data_mask = np.logical_and(
                self.data_mask,  distance_to_plane <= 0.0)
        else:
            raise RuntimeError("Unknown sign. must be + or -")


class FilterAnalyst(ParticleAnalystBase):
    """
    Analyze data through the Paraview filter
    """

    def __init__(self, input_data):
        super().__init__()
        self.input_data = input_data
        self.extractor = stg.VTKUnstructuredGridExtractor(self.input_data)
        self._do_load()


class FileAnalyst(ParticleAnalystBase):
    """
    Analyze data by directly opening the file
    """

    def __init__(self, project_name, input_path='.', output_path=None):
        super().__init__()
        self.project_name = project_name
        self.input_path = input_path
        self.file_number = None

        if output_path is None:
            self.export_path = os.path.join(input_path, "felspanalytic")
        else:
            self.export_path = output_path
        if not os.path.exists(self.export_path):
            os.mkdir(self.export_path)

        for f in os.listdir(input_path):
            if os.path.isfile(os.path.join(input_path, f)):
                regex_string = project_name + ptcl_file_suffix + r"_(\d+).vtu"
                m = re.search(regex_string, f)
                if m:
                    self.padded_file_number_digits = len(m.group(1))
                    break

    def load_file_number(self, file_number):
        '''
        Extracts all data from the vtu file and put them in the class storage
        load the data extractor and compute number of data points
        '''
        file_name = self._generate_file_name(file_number)
        self.file_number = file_number
        self.extractor = stg.VTKUnstructuredGridExtractor(file_name)
        self._do_load()

    def save_plot(self, fname=None,  **kwargs):
        if fname is None:
            fname = self.project_name + \
                stereonet_export_suffix + '_' + int_to_string(
                    self.file_number, self.padded_file_number_digits)  \
                + '.' + stereonet_export_filetype
        abs_path = os.path.join(self.export_path, fname)
        self.stereonet.save_plot(abs_path, **kwargs)

    def _generate_file_name(self, file_number):
        fname = self.project_name + ptcl_file_suffix + '_' + \
            int_to_string(file_number, self.padded_file_number_digits) + ".vtu"
        return os.path.join(self.input_path, fname)
